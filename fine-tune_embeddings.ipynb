{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME0vULeBBa4M02mnKJS3oh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a74d3a700cf4b0fbd3b403ee120428c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83c4b7114b504ce59bf6da6a526041a2",
              "IPY_MODEL_96c503c2330b448cafca3355f2dc5785",
              "IPY_MODEL_1352394a63bf419387644473ac8bb906"
            ],
            "layout": "IPY_MODEL_ef1f520b21084225ba0f3b7fc6fab752"
          }
        },
        "83c4b7114b504ce59bf6da6a526041a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6981b2803c9745538ae86ae2b64eb48d",
            "placeholder": "​",
            "style": "IPY_MODEL_280b1c36c8234edc8245ea5919955042",
            "value": "Generating train split: "
          }
        },
        "96c503c2330b448cafca3355f2dc5785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1eb49c074b746d4bcfa68dfd8e0e07a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_220a038bea6143c0a1448ae719b83789",
            "value": 1
          }
        },
        "1352394a63bf419387644473ac8bb906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f683ea14b2db48dbbb8a7951638516b9",
            "placeholder": "​",
            "style": "IPY_MODEL_fc3c31dba815410b88ff577d7283d250",
            "value": " 15/0 [00:00&lt;00:00, 290.27 examples/s]"
          }
        },
        "ef1f520b21084225ba0f3b7fc6fab752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6981b2803c9745538ae86ae2b64eb48d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "280b1c36c8234edc8245ea5919955042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1eb49c074b746d4bcfa68dfd8e0e07a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "220a038bea6143c0a1448ae719b83789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f683ea14b2db48dbbb8a7951638516b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc3c31dba815410b88ff577d7283d250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d64a01b8264a4a2784436b0f81b981e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb2e02f6eada4d8b8ea2444aaa4c3ec2",
              "IPY_MODEL_4a84e21ccc8546d6bd801203524c6f93",
              "IPY_MODEL_aed1436fc42a455a9f3c15f6cfb41ca1"
            ],
            "layout": "IPY_MODEL_ddb0e42cc7844fdf805e8b0b81c633be"
          }
        },
        "eb2e02f6eada4d8b8ea2444aaa4c3ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53cf0fed929a410395922ddfdd0544fc",
            "placeholder": "​",
            "style": "IPY_MODEL_231606789d324aaa9de2120ff9bd07d3",
            "value": "Map: 100%"
          }
        },
        "4a84e21ccc8546d6bd801203524c6f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaf08f63578944b9a84d28ba66a1f005",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_653bff26a5f2468aa7df0fbfc0df4ecf",
            "value": 15
          }
        },
        "aed1436fc42a455a9f3c15f6cfb41ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_294f35295a8640c4bf0cb81555b02e1c",
            "placeholder": "​",
            "style": "IPY_MODEL_654d471502084ad9ad5f676ac151b07b",
            "value": " 15/15 [00:00&lt;00:00, 373.70 examples/s]"
          }
        },
        "ddb0e42cc7844fdf805e8b0b81c633be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53cf0fed929a410395922ddfdd0544fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "231606789d324aaa9de2120ff9bd07d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaf08f63578944b9a84d28ba66a1f005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "653bff26a5f2468aa7df0fbfc0df4ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "294f35295a8640c4bf0cb81555b02e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "654d471502084ad9ad5f676ac151b07b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhoenixAlpha23/Fine-tune-embeddings/blob/main/fine-tune_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing dependencies\n",
        "tesseract-ocr ,datasets, sentence transformers,nltk and unstructured for documents."
      ],
      "metadata": {
        "id": "8WHrD-xIb6-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yrDQmMNFBx0S",
        "outputId": "8b94298d-975f-482a-8b7b-365fa24d504c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install poppler-utils tesseract-ocr\n",
        "!pip install datasets sentence-transformers google-generativeai\n",
        "!pip install -q --user --upgrade pillow\n",
        "!pip install -q unstructured[\"all-docs\"] pi_heif\n",
        "!pip install -q --upgrade unstructured\n",
        "!pip install --upgrade nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OHvuidTi9Pyb",
        "outputId": "edc73e0d-f1de-4817-f5b6-25952e6ddd21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting poppler-utils\n",
            "  Using cached poppler_utils-0.1.0-py3-none-any.whl.metadata (883 bytes)\n",
            "Collecting tesseract-ocr\n",
            "  Using cached tesseract-ocr-0.0.1.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.10/dist-packages (from poppler-utils) (8.1.7)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from tesseract-ocr) (3.0.11)\n",
            "Using cached poppler_utils-0.1.0-py3-none-any.whl (9.2 kB)\n",
            "Building wheels for collected packages: tesseract-ocr\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tesseract-ocr (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for tesseract-ocr\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for tesseract-ocr\n",
            "Failed to build tesseract-ocr\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tesseract-ocr)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.25.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.23.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install poppler-utils -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X9HOe6OBhau",
        "outputId": "a496242c-e0c7-426a-ac19-f49589535344"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (185.125.190.83)] [Connected to cloud.r-project.org (108.139.1\r                                                                                                    \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r0% [2 InRelease 15.6 kB/128 kB 12%] [Connecting to security.ubuntu.com (185.125.190.83)] [Connected \r                                                                                                    \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [2 InRelease 40.2 kB/128 kB 31%] [Waiting for headers] [Waiting for headers] [Waiting for headers\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connecti\r                                                                                                    \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcon\r                                                                                                    \rHit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcontent.net (185.125.190.\r                                                                                                    \rGet:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 257 kB in 2s (132 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six\n",
        "!apt-get install poppler-utils -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZFdCbraN0Ws",
        "outputId": "704bb897-9ca1-4320-ebb7-fa5e81ef29e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (20231228)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "# Find the directory where poppler-utils is installed\n",
        "poppler_path = os.path.join(sys.prefix, \"bin\")\n",
        "\n",
        "# Add the directory to the system PATH\n",
        "os.environ[\"PATH\"] += os.pathsep + poppler_path\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "ywoofD7UBAuG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF parsing and Text extraction"
      ],
      "metadata": {
        "id": "y3r_i8rFgedE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import os\n",
        "from unstructured.partition.pdf import partition_pdf\n",
        "from collections import Counter\n",
        "import warnings\n",
        "from pdfminer.pdfparser import PDFSyntaxError\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "def process_pdfs_in_folder(folder_path):\n",
        "    total_text = []  # To accumulate the text from all PDFs\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "        print(f\"Folder '{folder_path}' created.\")\n",
        "\n",
        "    #list of all PDF files in the folder\n",
        "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
        "\n",
        "    if not pdf_files:\n",
        "        print(\"No PDF files found in the folder.\")\n",
        "        return \"\"\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        pdf_path = os.path.join(folder_path, pdf_file)\n",
        "        print(f\"Processing: {pdf_path}\")\n",
        "        try:\n",
        "            #partition logic\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.filterwarnings(\"ignore\", category=UserWarning)  # Suppress warnings\n",
        "                elements = partition_pdf(pdf_path, strategy=\"auto\")\n",
        "            # Display the types of elements\n",
        "            display(Counter(type(element) for element in elements))\n",
        "            # Join the elements to form text and add it to total_text list\n",
        "            text = \"\\n\\n\".join([str(el) for el in elements])\n",
        "            total_text.append(text)\n",
        "        except PDFSyntaxError:\n",
        "            print(f\"Skipping {pdf_file}: Invalid or corrupted PDF file.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {pdf_file}: {e}\")\n",
        "\n",
        "    # Return the total concatenated text\n",
        "    return \"\\n\\n\".join(total_text)\n",
        "\n",
        "\n",
        "folder_path = \"data\"\n",
        "all_text = process_pdfs_in_folder(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "82JDqHw69PWv",
        "outputId": "89f1762c-cdb6-49b9-ab0f-338873e30743"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: data/Schargesheet-1.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Counter({unstructured.documents.elements.Title: 57,\n",
              "         unstructured.documents.elements.Text: 9,\n",
              "         unstructured.documents.elements.NarrativeText: 36,\n",
              "         unstructured.documents.elements.ListItem: 4})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: data/fNy5D2yT2Lgrpup9gNVMg3hSbRH6pVBrmcO6LNhI.pdf\n",
            "Error processing fNy5D2yT2Lgrpup9gNVMg3hSbRH6pVBrmcO6LNhI.pdf: Unable to get page count.\n",
            "Syntax Error: Couldn't find trailer dictionary\n",
            "Syntax Error: Couldn't find trailer dictionary\n",
            "Syntax Error: Couldn't read xref table\n",
            "\n",
            "Processing: data/scs1-1.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Counter({unstructured.documents.elements.Title: 152,\n",
              "         unstructured.documents.elements.Text: 32,\n",
              "         unstructured.documents.elements.ListItem: 11,\n",
              "         unstructured.documents.elements.NarrativeText: 56})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-defined text chunking"
      ],
      "metadata": {
        "id": "1GATzqmrgzG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def nltk_based_splitter(text: str, chunk_size: int, overlap: int) -> list:\n",
        "    \"\"\"\n",
        "    Splits the input text into chunks of a specified size, with optional overlap between chunks.\n",
        "\n",
        "    Parameters:\n",
        "    - text: The input text to be split.\n",
        "    - chunk_size: The maximum size of each chunk (in terms of characters).\n",
        "    - overlap: The number of overlapping characters between consecutive chunks.\n",
        "\n",
        "    Returns:\n",
        "    - A list of text chunks, with or without overlap.\n",
        "    \"\"\"\n",
        "\n",
        "    from nltk.tokenize import sent_tokenize\n",
        "\n",
        "    # Tokenize the input text into individual sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # If the current chunk plus the next sentence doesn't exceed the chunk size, add the sentence to the chunk\n",
        "        if len(current_chunk) + len(sentence) <= chunk_size:\n",
        "            current_chunk += \" \" + sentence\n",
        "        else:\n",
        "            # Otherwise, add the current chunk to the list of chunks and start a new chunk with the current sentence\n",
        "            chunks.append(current_chunk.strip())  # Strip to remove leading spaces\n",
        "            current_chunk = sentence\n",
        "\n",
        "    # After the loop, if there is any leftover text in the current chunk, add it to the list of chunks\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    # Handle overlap if it's specified (overlap > 0)\n",
        "    if overlap > 0:\n",
        "        overlapping_chunks = []\n",
        "        for i in range(len(chunks)):\n",
        "            if i > 0:\n",
        "                # Calculate the start index for overlap from the previous chunk\n",
        "                start_overlap = max(0, len(chunks[i-1]) - overlap)\n",
        "                # Combine the overlapping portion of the previous chunk with the current chunk\n",
        "                chunk_with_overlap = chunks[i-1][start_overlap:] + \" \" + chunks[i]\n",
        "                # Append the combined chunk, making sure it's not longer than chunk_size\n",
        "                overlapping_chunks.append(chunk_with_overlap[:chunk_size])\n",
        "            else:\n",
        "                # For the first chunk, there's no previous chunk to overlap with\n",
        "                overlapping_chunks.append(chunks[i][:chunk_size])\n",
        "\n",
        "        return overlapping_chunks  # Return the list of chunks with overlap\n",
        "\n",
        "    # If overlap is 0, return the non-overlapping chunks\n",
        "    return chunks\n",
        "\n",
        "chunks = nltk_based_splitter(text=all_text,\n",
        "                                  chunk_size=2048,\n",
        "                                  overlap=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0muUCW4e9PSq",
        "outputId": "28cd782d-1fde-4af1-9d0e-a9319bb7c420"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset generation\n",
        "To create Question and Answer pairs from our dataset,using gemini API."
      ],
      "metadata": {
        "id": "pYYmjMnig_U0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "\n",
        "# Replace with your valid Google API key\n",
        "GOOGLE_API_KEY = \"YOUR_API_KEY\"\n",
        "\n",
        "# Prompt generator with an explicit request for structured output\n",
        "def prompt(text_chunk):\n",
        "    return f\"\"\"\n",
        "    Based on the following text, generate one Question and its corresponding Answer.\n",
        "    Please format the output as follows:\n",
        "    Question: [Your question]\n",
        "    Answer: [Your answer]\n",
        "\n",
        "    Text: {text_chunk}\n",
        "    \"\"\"\n",
        "# Function to interact with Google's Gemini and return a QA pair\n",
        "def generate_with_gemini(text_chunk:str, temperature:float, model_name:str):\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    generation_config = {\"temperature\": temperature}\n",
        "\n",
        "    # Initialize the generative model\n",
        "    gen_model = genai.GenerativeModel(model_name, generation_config=generation_config)\n",
        "\n",
        "    # Generate response based on the prompt\n",
        "    response = gen_model.generate_content(prompt(text_chunk))\n",
        "\n",
        "    # Extract question and answer from response using keyword\n",
        "    try:\n",
        "        question, answer = response.text.split(\"Answer:\", 1)\n",
        "        question = question.replace(\"Question:\", \"\").strip()\n",
        "        answer = answer.strip()\n",
        "    except ValueError:\n",
        "        question, answer = \"N/A\", \"N/A\"  # Handle unexpected format in response\n",
        "\n",
        "    return question, answer"
      ],
      "metadata": {
        "id": "pixgoiX69PPD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "process_text_chunks function is used to create QnA pairs for each text chunkusing gemini model."
      ],
      "metadata": {
        "id": "-JWH4_VChXfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text_chunks(text_chunks:list, temperature:int, model_name=str):\n",
        "    \"\"\"\n",
        "    Processes a list of text chunks to generate questions and answers using a specified model.\n",
        "\n",
        "    Parameters:\n",
        "    - text_chunks: A list of text chunks to process.\n",
        "    - temperature: The sampling temperature to control randomness in the generated outputs.\n",
        "    - model_name: The name of the model to use for generating questions and answers.\n",
        "\n",
        "    Returns:\n",
        "    - A Pandas DataFrame containing the text chunks, questions, and answers.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Iterate through each text chunk\n",
        "    for chunk in text_chunks:\n",
        "        question, answer = generate_with_gemini(chunk, temperature, model_name)\n",
        "        results.append({\"Text Chunk\": chunk, \"Question\": question, \"Answer\": answer})\n",
        "\n",
        "    # Convert results into a Pandas DataFrame\n",
        "    df = pd.DataFrame(results)\n",
        "    return df\n",
        "# Process the text chunks and get the DataFrame\n",
        "df_results = process_text_chunks(text_chunks=chunks,\n",
        "                                 temperature=0.7,\n",
        "                                 model_name=\"gemini-1.5-flash\")\n",
        "df_results.to_csv(\"generated_qa_pairs.csv\", index=False)"
      ],
      "metadata": {
        "id": "UmFXRSnd9PIu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the CSV file into a Hugging Face Dataset"
      ],
      "metadata": {
        "id": "UMAKO2lXiANN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('csv', data_files='generated_qa_pairs.csv')\n",
        "\n",
        "def process_example(example, idx):\n",
        "    return {\n",
        "        \"id\": idx,  #unique ID based on the index\n",
        "        \"anchor\": example[\"Question\"],\n",
        "        \"positive\": example[\"Answer\"]\n",
        "    }\n",
        "dataset = dataset.map(process_example,\n",
        "                      with_indices=True ,\n",
        "                      remove_columns=[\"Text Chunk\", \"Question\", \"Answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "1a74d3a700cf4b0fbd3b403ee120428c",
            "83c4b7114b504ce59bf6da6a526041a2",
            "96c503c2330b448cafca3355f2dc5785",
            "1352394a63bf419387644473ac8bb906",
            "ef1f520b21084225ba0f3b7fc6fab752",
            "6981b2803c9745538ae86ae2b64eb48d",
            "280b1c36c8234edc8245ea5919955042",
            "b1eb49c074b746d4bcfa68dfd8e0e07a",
            "220a038bea6143c0a1448ae719b83789",
            "f683ea14b2db48dbbb8a7951638516b9",
            "fc3c31dba815410b88ff577d7283d250",
            "d64a01b8264a4a2784436b0f81b981e5",
            "eb2e02f6eada4d8b8ea2444aaa4c3ec2",
            "4a84e21ccc8546d6bd801203524c6f93",
            "aed1436fc42a455a9f3c15f6cfb41ca1",
            "ddb0e42cc7844fdf805e8b0b81c633be",
            "53cf0fed929a410395922ddfdd0544fc",
            "231606789d324aaa9de2120ff9bd07d3",
            "eaf08f63578944b9a84d28ba66a1f005",
            "653bff26a5f2468aa7df0fbfc0df4ecf",
            "294f35295a8640c4bf0cb81555b02e1c",
            "654d471502084ad9ad5f676ac151b07b"
          ]
        },
        "id": "In7nZh7ZGS16",
        "outputId": "c5c74fae-1783-4806-8e32-1d4873eecee6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a74d3a700cf4b0fbd3b403ee120428c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d64a01b8264a4a2784436b0f81b981e5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used the BAAI/bge-base-en-v1.5 model, developed by BAAI (Beijing Academy of Artificial Intelligence) since it is a powerful text embedding model, it excels at various NLP tasks and has been shown to perform well on benchmarks like MTEB and C-MTEB.\n",
        "\n",
        "The bge-base-en model is a good choice for applications with limited computational resources, such as this one:)"
      ],
      "metadata": {
        "id": "4vuVYx5ciJsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.evaluation import (\n",
        "    InformationRetrievalEvaluator,\n",
        "    SequentialEvaluator,\n",
        ")\n",
        "from sentence_transformers.util import cos_sim\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
        "\n",
        "\n",
        "model_id = \"BAAI/bge-base-en-v1.5\"\n",
        "\n",
        "# Load model\n",
        "model = SentenceTransformer(\n",
        "    model_id, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")"
      ],
      "metadata": {
        "id": "cYEdI7pUGSiM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Matryoshka Fine-tuning:** Fine-tunes the BGE model using Matryoshka loss to enhance retrieval accuracy."
      ],
      "metadata": {
        "id": "6TGgjhExkQ5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why to you use 🪆 Matryoshka Embedding models?\n",
        "Such variable-size embedding modelshelp in:\n",
        "\n",
        "* Shortlisting and reranking: Rather than performing your downstream task (e.g., nearest neighbor search) on the full embeddings, you can shrink the embeddings to a smaller size and very efficiently \"shortlist\" your embeddings.\n",
        "\n",
        "* Afterwards, you can process the remaining embeddings using their full dimensionality.\n",
        "\n",
        "* *Trade-offs:* Matryoshka models will allow you to scale your embedding solutions to your desired storage cost, processing speed, and performance."
      ],
      "metadata": {
        "id": "6yr9ZNTCjP_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Essential to set them from large to small, like the matryoshka dolls.\n",
        "matryoshka_dimensions = [768, 512, 256, 128, 64]\n",
        "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
        "train_loss = MatryoshkaLoss(\n",
        "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
        ")"
      ],
      "metadata": {
        "id": "Pcy5QqyKGSOr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformerTrainingArguments\n",
        "from sentence_transformers.training_args import BatchSamplers\n",
        "\n",
        "# define training arguments\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir=\"bge-finetuned\",                 # output directory and hugging face model ID\n",
        "    num_train_epochs=5,                         # number of epochs\n",
        "    per_device_train_batch_size=4,              # train batch size\n",
        "    gradient_accumulation_steps=16,             # for a global batch size of 512\n",
        "    per_device_eval_batch_size=16,              # evaluation batch size\n",
        "    warmup_ratio=0.1,                           # warmup ratio\n",
        "    learning_rate=2e-5,                         # learning rate\n",
        "    lr_scheduler_type=\"cosine\",                 # use constant learning rate scheduler\n",
        "    optim=\"adamw_torch_fused\",                  # use fused adamw optimizer\n",
        "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
        "    eval_strategy=\"epoch\",                      # evaluate after each epoch\n",
        "    save_strategy=\"epoch\",                      # save after each epoch\n",
        "    logging_steps=10,                           # log every 10 steps\n",
        "    save_total_limit=3,                         # save only the last 3 models\n",
        "    load_best_model_at_end=True,                # load the best model when training ends\n",
        "    metric_for_best_model=\"eval_dim_128_cosine_ndcg@10\",  # Optimizing for the best ndcg@10 score for the 128 dimension\n",
        ")"
      ],
      "metadata": {
        "id": "Gpqz92b7GRmR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = dict(\n",
        "    zip(dataset['train']['id'],\n",
        "        dataset['train']['positive'])\n",
        ")  # Our corpus (cid => document)\n",
        "\n",
        "queries = dict(\n",
        "    zip(dataset['train']['id'],\n",
        "        dataset['train']['anchor'])\n",
        ")  # Our queries (qid => question)\n",
        "\n",
        "# Create a mapping of relevant documents for each query\n",
        "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
        "for q_id in queries:\n",
        "    relevant_docs[q_id] = [q_id]\n",
        "\n",
        "matryoshka_evaluators = []\n",
        "# Iterate over the different dimensions\n",
        "for dim in matryoshka_dimensions:\n",
        "    ir_evaluator = InformationRetrievalEvaluator(\n",
        "        queries=queries,\n",
        "        corpus=corpus,\n",
        "        relevant_docs=relevant_docs,\n",
        "        name=f\"dim_{dim}\",\n",
        "        truncate_dim=dim,  # Truncate the embeddings to a certain dimension\n",
        "        score_functions={\"cosine\": cos_sim},\n",
        "    )\n",
        "    matryoshka_evaluators.append(ir_evaluator)\n",
        "#Create evaluator\n",
        "evaluator = SequentialEvaluator(matryoshka_evaluators)"
      ],
      "metadata": {
        "id": "6i-WpqlqHCCX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation before training\n",
        "results = evaluator(model)\n",
        "\n",
        "for dim in matryoshka_dimensions:\n",
        "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
        "    print(f\"{key}: {results[key]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5ctbS6mHEEc",
        "outputId": "eb70218a-b0be-4806-e352-aff8ce6af56a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dim_768_cosine_ndcg@10: 0.8454569391354841\n",
            "dim_512_cosine_ndcg@10: 0.8454569391354841\n",
            "dim_256_cosine_ndcg@10: 0.8454569391354841\n",
            "dim_128_cosine_ndcg@10: 0.8345188373870667\n",
            "dim_64_cosine_ndcg@10: 0.7941518299738394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformerTrainer\n",
        "\n",
        "# Split the dataset into train and eval sets\n",
        "train_dataset = dataset['train']\n",
        "eval_dataset = dataset['train']\n",
        "\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model, # our embedding model\n",
        "    args=args,  # defined above\n",
        "    train_dataset=train_dataset.select_columns(\n",
        "        [\"positive\", \"anchor\"]\n",
        "    ),\n",
        "    eval_dataset=eval_dataset.select_columns(\n",
        "        [\"positive\", \"anchor\"]\n",
        "    ),\n",
        "    loss=train_loss, # Matryoshka loss\n",
        "    evaluator=evaluator, # Sequential Evaluator\n",
        ")"
      ],
      "metadata": {
        "id": "laed5hYiLqUP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start training\n",
        "trainer.train()\n",
        "# save the best model\n",
        "trainer.save_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "BgCoJxMAL35d",
        "outputId": "1a9ad6b5-401e-47a2-ae57-cd70a88564d7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.data_collator:Column 'anchor' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n",
            "dataset = dataset.select_columns(['anchor', 'positive', 'negative'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 07:08, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Dim 768 Cosine Accuracy@1</th>\n",
              "      <th>Dim 768 Cosine Accuracy@3</th>\n",
              "      <th>Dim 768 Cosine Accuracy@5</th>\n",
              "      <th>Dim 768 Cosine Accuracy@10</th>\n",
              "      <th>Dim 768 Cosine Precision@1</th>\n",
              "      <th>Dim 768 Cosine Precision@3</th>\n",
              "      <th>Dim 768 Cosine Precision@5</th>\n",
              "      <th>Dim 768 Cosine Precision@10</th>\n",
              "      <th>Dim 768 Cosine Recall@1</th>\n",
              "      <th>Dim 768 Cosine Recall@3</th>\n",
              "      <th>Dim 768 Cosine Recall@5</th>\n",
              "      <th>Dim 768 Cosine Recall@10</th>\n",
              "      <th>Dim 768 Cosine Ndcg@10</th>\n",
              "      <th>Dim 768 Cosine Mrr@10</th>\n",
              "      <th>Dim 768 Cosine Map@100</th>\n",
              "      <th>Dim 512 Cosine Accuracy@1</th>\n",
              "      <th>Dim 512 Cosine Accuracy@3</th>\n",
              "      <th>Dim 512 Cosine Accuracy@5</th>\n",
              "      <th>Dim 512 Cosine Accuracy@10</th>\n",
              "      <th>Dim 512 Cosine Precision@1</th>\n",
              "      <th>Dim 512 Cosine Precision@3</th>\n",
              "      <th>Dim 512 Cosine Precision@5</th>\n",
              "      <th>Dim 512 Cosine Precision@10</th>\n",
              "      <th>Dim 512 Cosine Recall@1</th>\n",
              "      <th>Dim 512 Cosine Recall@3</th>\n",
              "      <th>Dim 512 Cosine Recall@5</th>\n",
              "      <th>Dim 512 Cosine Recall@10</th>\n",
              "      <th>Dim 512 Cosine Ndcg@10</th>\n",
              "      <th>Dim 512 Cosine Mrr@10</th>\n",
              "      <th>Dim 512 Cosine Map@100</th>\n",
              "      <th>Dim 256 Cosine Accuracy@1</th>\n",
              "      <th>Dim 256 Cosine Accuracy@3</th>\n",
              "      <th>Dim 256 Cosine Accuracy@5</th>\n",
              "      <th>Dim 256 Cosine Accuracy@10</th>\n",
              "      <th>Dim 256 Cosine Precision@1</th>\n",
              "      <th>Dim 256 Cosine Precision@3</th>\n",
              "      <th>Dim 256 Cosine Precision@5</th>\n",
              "      <th>Dim 256 Cosine Precision@10</th>\n",
              "      <th>Dim 256 Cosine Recall@1</th>\n",
              "      <th>Dim 256 Cosine Recall@3</th>\n",
              "      <th>Dim 256 Cosine Recall@5</th>\n",
              "      <th>Dim 256 Cosine Recall@10</th>\n",
              "      <th>Dim 256 Cosine Ndcg@10</th>\n",
              "      <th>Dim 256 Cosine Mrr@10</th>\n",
              "      <th>Dim 256 Cosine Map@100</th>\n",
              "      <th>Dim 128 Cosine Accuracy@1</th>\n",
              "      <th>Dim 128 Cosine Accuracy@3</th>\n",
              "      <th>Dim 128 Cosine Accuracy@5</th>\n",
              "      <th>Dim 128 Cosine Accuracy@10</th>\n",
              "      <th>Dim 128 Cosine Precision@1</th>\n",
              "      <th>Dim 128 Cosine Precision@3</th>\n",
              "      <th>Dim 128 Cosine Precision@5</th>\n",
              "      <th>Dim 128 Cosine Precision@10</th>\n",
              "      <th>Dim 128 Cosine Recall@1</th>\n",
              "      <th>Dim 128 Cosine Recall@3</th>\n",
              "      <th>Dim 128 Cosine Recall@5</th>\n",
              "      <th>Dim 128 Cosine Recall@10</th>\n",
              "      <th>Dim 128 Cosine Ndcg@10</th>\n",
              "      <th>Dim 128 Cosine Mrr@10</th>\n",
              "      <th>Dim 128 Cosine Map@100</th>\n",
              "      <th>Dim 64 Cosine Accuracy@1</th>\n",
              "      <th>Dim 64 Cosine Accuracy@3</th>\n",
              "      <th>Dim 64 Cosine Accuracy@5</th>\n",
              "      <th>Dim 64 Cosine Accuracy@10</th>\n",
              "      <th>Dim 64 Cosine Precision@1</th>\n",
              "      <th>Dim 64 Cosine Precision@3</th>\n",
              "      <th>Dim 64 Cosine Precision@5</th>\n",
              "      <th>Dim 64 Cosine Precision@10</th>\n",
              "      <th>Dim 64 Cosine Recall@1</th>\n",
              "      <th>Dim 64 Cosine Recall@3</th>\n",
              "      <th>Dim 64 Cosine Recall@5</th>\n",
              "      <th>Dim 64 Cosine Recall@10</th>\n",
              "      <th>Dim 64 Cosine Ndcg@10</th>\n",
              "      <th>Dim 64 Cosine Mrr@10</th>\n",
              "      <th>Dim 64 Cosine Map@100</th>\n",
              "      <th>Sequential Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.759125</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.845457</td>\n",
              "      <td>0.795556</td>\n",
              "      <td>0.795556</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.845457</td>\n",
              "      <td>0.795556</td>\n",
              "      <td>0.795556</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.845457</td>\n",
              "      <td>0.795556</td>\n",
              "      <td>0.795556</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.288889</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.093333</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.834519</td>\n",
              "      <td>0.802222</td>\n",
              "      <td>0.807350</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.794152</td>\n",
              "      <td>0.728889</td>\n",
              "      <td>0.728889</td>\n",
              "      <td>0.794152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.886112</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.849933</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.874538</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.899142</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.093333</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.850791</td>\n",
              "      <td>0.822222</td>\n",
              "      <td>0.827778</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.874538</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.874538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.903320</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.884124</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.884124</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.904107</td>\n",
              "      <td>0.872222</td>\n",
              "      <td>0.872222</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.870062</td>\n",
              "      <td>0.828889</td>\n",
              "      <td>0.828889</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.892853</td>\n",
              "      <td>0.855556</td>\n",
              "      <td>0.855556</td>\n",
              "      <td>0.892853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.479758</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.884124</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.884124</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.926186</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.873013</td>\n",
              "      <td>0.831746</td>\n",
              "      <td>0.831746</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.892853</td>\n",
              "      <td>0.855556</td>\n",
              "      <td>0.855556</td>\n",
              "      <td>0.892853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.363729</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.884124</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.884124</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.926186</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.874538</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.917457</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.917457</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "fine_tuned_model = SentenceTransformer(\n",
        "    args.output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "# Evaluatation of model after fine-tuning\n",
        "results = evaluator(fine_tuned_model)\n",
        "\n",
        "#main score\n",
        "for dim in matryoshka_dimensions:\n",
        "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
        "    print(f\"{key}: {results[key]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqRKGf9_M0rY",
        "outputId": "582f31cc-b54d-4b28-ec54-c6ee8b69242e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dim_768_cosine_ndcg@10: 0.884123967142861\n",
            "dim_512_cosine_ndcg@10: 0.884123967142861\n",
            "dim_256_cosine_ndcg@10: 0.9261859507142916\n",
            "dim_128_cosine_ndcg@10: 0.8745377796167292\n",
            "dim_64_cosine_ndcg@10: 0.9174573004761943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "#Required:\n",
        "# - `queries`: A dictionary where keys are query IDs and values are query texts.\n",
        "# - `corpus`: A dictionary where keys are document IDs and values are document texts.\n",
        "# - `relevant_docs`: A dictionary where keys are query IDs and values are lists of relevant document IDs.\n",
        "\n",
        "def calculate_ndcg(model, queries, corpus, relevant_docs, k=10):\n",
        "    \"\"\"\n",
        "    Calculates the NDCG@k score for a given model, queries, corpus, and relevant documents.\n",
        "\n",
        "    Args:\n",
        "        model: The SentenceTransformer model.\n",
        "        queries: A dictionary of queries (query_id => query_text).\n",
        "        corpus: A dictionary of documents (doc_id => doc_text).\n",
        "        relevant_docs: A dictionary of relevant documents for each query (query_id => [relevant_doc_ids]).\n",
        "        k: The number of top results to consider for NDCG calculation.\n",
        "\n",
        "    Returns:\n",
        "        The average NDCG@k score across all queries.\n",
        "    \"\"\"\n",
        "\n",
        "    ndcg_scores = []\n",
        "\n",
        "    for query_id, query_text in queries.items():\n",
        "        # Encode the query\n",
        "        query_embedding = model.encode(query_text)\n",
        "\n",
        "        # Encode all documents in the corpus\n",
        "        document_embeddings = model.encode(list(corpus.values()))\n",
        "\n",
        "        # Calculate cosine similarities between query and documents\n",
        "        similarities = cos_sim(query_embedding, document_embeddings).cpu().numpy()[0]\n",
        "\n",
        "        # Get the indices of the top k most similar documents\n",
        "        top_k_indices = similarities.argsort()[-k:][::-1]\n",
        "\n",
        "        # Get the IDs of the top k documents\n",
        "        retrieved_doc_ids = [list(corpus.keys())[i] for i in top_k_indices]\n",
        "\n",
        "        # Create a binary relevance vector (1 if document is relevant, 0 otherwise)\n",
        "        relevance = [1 if doc_id in relevant_docs[query_id] else 0 for doc_id in retrieved_doc_ids]\n",
        "\n",
        "        # Calculate NDCG@k for this query\n",
        "        ndcg_scores.append(ndcg_score([relevance], [similarities[top_k_indices]]))\n",
        "\n",
        "    # Return the average NDCG@k score\n",
        "    return sum(ndcg_scores) / len(ndcg_scores)\n",
        "\n",
        "\n",
        "# Calculate and print the NDCG@10 score\n",
        "ndcg_at_10 = calculate_ndcg(model=fine_tuned_model, queries=queries, corpus=corpus, relevant_docs=relevant_docs)\n",
        "print(f\"NDCG@10: {ndcg_at_10}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZujLLpRak2t",
        "outputId": "744fb4b7-4eb2-48cd-8a60-b9009479ea80"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDCG@10: 0.884123967142861\n"
          ]
        }
      ]
    }
  ]
}